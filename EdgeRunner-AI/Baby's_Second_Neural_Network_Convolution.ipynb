{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baby's Second Neural Network: Convolution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwgb93/SIAM-Neural-Nets/blob/main/EdgeRunner-AI/Baby's_Second_Neural_Network_Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtcYiUND0k0a"
      },
      "source": [
        "#My Second Neural Network: Convolution\n",
        "\n",
        "Convolutional Neural nets take a long time to run. Make sure you're connected to a GPU by clicking\n",
        "##Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU\n",
        "\n",
        "When we're dealing with image classificaiton, we want to identify features in an image that are clustered close together. For example, if we want to tell the difference between an 8 and a 9, we need to be able to distinguish between the pixels that make the bottom loop of an 8 and the stem of a 9.\n",
        "\n",
        "Once again, we'll start with some bookkeeping. You'll notice this looks different that before. By importing exactly what we need up front, we can eliminate some of the messy-looking code later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whUShDuM06gn"
      },
      "source": [
        "from keras.datasets.mnist import load_data\n",
        "\n",
        "from keras import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization, GlobalMaxPooling2D, SpatialDropout2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.optimizers.schedules import CosineDecay"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kql2bjeEyJLg"
      },
      "source": [
        "Next we'll download the data we are going to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaWv1QDwyMUp"
      },
      "source": [
        "# the data is already split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = load_data() #Notice how this is much cleaner than before.\n",
        "\n",
        "# Since we're dealing with image data, we need to reshape each vector\n",
        "# This lets our network learn using pixels that are close together\n",
        "#x_train, x_test = x_train / 255.0, x_test / 255.0 # consider uncommenting this to try with normalization\n",
        "# OR\n",
        "#x_train, x_test = x_train / 127.5 - 1, x_test / 127.5 - 1 # Normalized from -1 to 1 (good with tanh)\n",
        "# OR\n",
        "#x_train, x_test = (x_train - 20) / 200.0, (x_test - 20) / 200 # mean 0, variance 1 approximately\n",
        "x_train = x_train.reshape(len(x_train), 28, 28, 1)\n",
        "x_test = x_test.reshape(len(x_test), 28, 28, 1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdQVNW3a4g5m"
      },
      "source": [
        "Let's build our neural network again. This time, we'll have several convolutional layers.\n",
        "\n",
        "We'll start with the input layer. Since we have a 28x28 image, we need 784 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egfEAbZp4o1e"
      },
      "source": [
        "model = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    #Dropout(0.5),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ug-hL497PYD"
      },
      "source": [
        "Now, let's train the neural network!\n",
        "\n",
        "We'll start a little differently than before. First, we'll use minibatches. This lets us compute a noisy estimate of the gradients at each time step, helping speed up training and escape local minima.\n",
        "\n",
        "Additionally, we will randomly split the dataset into a training and validation set. Much like a test set, this will separate some of the images so they are NOT used for training. We can see how well the trained network is performing on new data as we go. This lets us tune parameters as we go to avoid overfitting.\n",
        "\n",
        "Finally, we'll save the best model as we go, so we keep the best model before overfitting starts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqBbGbg96-eW"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('best_MNIST_CNN_model.keras', monitor='val_loss', save_best_only=True, save_freq=\"epoch\")\n",
        "callbacks_list=[model_checkpoint]\n",
        "\n",
        "model.fit(x=x_train, y=y_train, batch_size=50, epochs=10, verbose=1, validation_split=0.2, callbacks=callbacks_list)\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6fT02rc7p1a"
      },
      "source": [
        "Wow! Nearly 99% accuracy, in under a minute.\n",
        "How can we do better?\n",
        "\n",
        "Let's go a little bigger, adding dense layers after our convolutional layers.\n",
        "\n",
        "\n",
        "We are going to recreate one of the very first convolutional neural networks\n",
        "\n",
        "#LeNet\n",
        "\n",
        "~http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf~\n",
        "https://www.iro.umontreal.ca/~lisa/pointeurs/lecun-01a.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljiu7dvF7kOX"
      },
      "source": [
        "model2 = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(6, kernel_size=(5, 5), padding=\"same\", activation=\"tanh\"),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, kernel_size=(5, 5), activation=\"tanh\"),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(120, kernel_size=(5, 5), activation=\"tanh\"),\n",
        "    Flatten(),\n",
        "    Dense(84, activation=\"tanh\"),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKKJ9w6H-ln8"
      },
      "source": [
        "Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vbgN13B9Zqn"
      },
      "source": [
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch < 2:\n",
        "      return 5e-4\n",
        "    elif epoch < 5:\n",
        "      return 2e-4\n",
        "    elif epoch < 8:\n",
        "      return 1e-4\n",
        "    elif epoch < 12:\n",
        "      return 5e-5\n",
        "    else:\n",
        "      return 1e-5\n",
        "\n",
        "callbacks_list=[LearningRateScheduler(lr_scheduler, verbose=1)]\n",
        "\n",
        "model2.fit(x=x_train,y=y_train, batch_size=64, epochs=20, verbose=1, validation_split=0.2) #, callbacks=callbacks_list)\n",
        "model2.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Af3l1SJCS-"
      },
      "source": [
        "That's not much better, but we're using 1998 technology.\n",
        "\n",
        "Let's jump forward a few decades, by using ReLU activation, MaxPooling, Adam, and a Learning Rate Scheduler.\n",
        "\n",
        "That's a little better! But we're plateauing around 99%. Squeezing those last few bits of performance out is tricky, without some serious tweaks like data augmentation and ensemble networks.\n",
        "\n",
        "Okay, now let's go for state of the art.\n",
        "\n",
        "This is called SimpleNet: 13 convolutional layers, with Batch Normalization every layer, and Dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWfigDuJSCT"
      },
      "source": [
        "# SimpleNet\n",
        "https://arxiv.org/abs/1608.06037"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95mXT-vpJUbE"
      },
      "source": [
        "model3 = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Dropout(0.1),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Conv2D(512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(2048, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(256, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEc3dF5lOh2G"
      },
      "source": [
        "model3.compile(optimizer = Adam(learning_rate=0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-t6mGaswdJT"
      },
      "source": [
        "That's a lot of parameters!\n",
        "\n",
        "As a result, this is going to take a little longer to train. Make sure you're connected to GPU runtime!\n",
        "\n",
        "We're also going to do a few tricks to make sure we get the best results.\n",
        "\n",
        "First, we'll make sure that we only save the best model. That way, if we start to overfit, we can resume training from what worked best.\n",
        "\n",
        "Next, we'll start with a high learning rate, then decrease it over time. This should help us escape some local minima, and keep learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBzeWgDAOh38"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('best_SimpleNet.keras', monitor='val_loss', save_best_only=True, save_freq=\"epoch\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=1, verbose=1, factor=0.2, min_lr=1e-6)\n",
        "\n",
        "callbacks_list=[model_checkpoint, reduce_lr]\n",
        "\n",
        "model3.fit(x=x_train, y=y_train, batch_size=100, epochs=10, verbose=1, validation_split=0.2, callbacks=callbacks_list)\n",
        "model3.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9uSwm42Kq2L"
      },
      "source": [
        "#SimpleNet Smol\n",
        "\n",
        "This takes the same ideas as above, but uses a 5x fewer parameters, and a special 2D version of Dropout after every BatchNorm layer to really try and avoid overfitting.\n",
        "\n",
        "Let's see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zj-2_Z2ckon"
      },
      "source": [
        "model4 = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(66, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(144, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(144, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(178, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(216, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    GlobalMaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Decay: https://keras.io/api/optimizers/learning_rate_schedules/cosine_decay/"
      ],
      "metadata": {
        "id": "uMhaiSB5vtMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=s2NkEYVp_44\n",
        "cosine_decay_scheduler = CosineDecay(\n",
        "    initial_lr=, decay_steps=, warmup_target=, warmup_steps=\n",
        "    )"
      ],
      "metadata": {
        "id": "8m5_wLh1PgTt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH4bmhVXdarE"
      },
      "source": [
        "model4.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3RfMxbydbg3"
      },
      "source": [
        "model_checkpoint2 = ModelCheckpoint('best_SimpleNet_Smol.keras', monitor='val_loss', save_best_only=True, save_freq=\"epoch\")\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_accuracy', patience=1, verbose=1, factor=0.2, min_lr=1e-6)\n",
        "\n",
        "callbacks_list=[model_checkpoint2, reduce_lr2]\n",
        "\n",
        "model4.fit(x=x_train, y=y_train, batch_size=100, epochs=10, verbose=1, validation_split=0.2, callbacks=callbacks_list)\n",
        "model4.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO3TGiE6T4fN",
        "outputId": "69dfac04-4780-4e1c-a9a3-02f529e984cd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - 6ms/step - accuracy: 0.9971 - loss: 0.0095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.009528209455311298, 0.9970999956130981]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge\n",
        "\n",
        "Try to get a test-set accuracy higher than 0.9971.\n",
        "\n",
        "Rules (Hard Mode):\n",
        "- Must be a single neural network\n",
        "- Network must be trained on the training data\n",
        "- No augmentations\n",
        "- No ensembles\n",
        "\n",
        "Ranks:\n",
        "- \\> 99.5 - Bronze\n",
        "- \\> 99.6 - Silver\n",
        "- \\> 99.7 - Gold\n",
        "- \\> 99.75 - World record!\n",
        "\n",
        "Unlimited Class (augmentations and ensembles allowed):\n",
        "- \\> 99.8 - Platinum\n",
        "- \\> 99.9 - Diamond\n",
        "- \\> 99.91 - World record? (unclear - there are 100%s on Kaggle\n",
        "- \\> 99.96 - Unpossible (there are errors in the dataset)\n",
        "\n",
        "Winner(s) get(s) a something. Maybe.\n",
        "\n",
        "### Helpful Resources\n",
        "- Optimizers: https://keras.io/api/optimizers/ (`!pip install -U keras` then try to get Muon working)\n",
        "- Activations: https://keras.io/api/layers/activations/\n",
        "- Layers: https://keras.io/api/layers/"
      ],
      "metadata": {
        "id": "HEI29fACvwkH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmIXIoKCVdid"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}