{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baby's Second Neural Network: Convolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBwmDIJ94t5GB6+7OR1vVG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwgb93/SIAM-Neural-Nets/blob/main/Baby's_Second_Neural_Network_Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtcYiUND0k0a"
      },
      "source": [
        "#My First Neural Network: Convolution\n",
        "\n",
        "Convolutional Neural nets take a long time to run. Make sure you're connected to a GPU by clicking \n",
        "##Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU\n",
        "\n",
        "When we're dealing with image classificaiton, we want to identify features in an image that are clustered close together. For example, if we want to tell the difference between an 8 and a 9, we need to be able to distinguish between the pixels that make the bottom loop of an 8 and the stem of a 9.\n",
        "\n",
        "Once again, we'll start with some bookkeeping. You'll notice this looks different that before. By importing exactly what we need up front, we can eliminate some of the messy-looking code later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whUShDuM06gn"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization, GlobalMaxPooling2D, SpatialDropout2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kql2bjeEyJLg"
      },
      "source": [
        "Next we'll download the data we are going to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaWv1QDwyMUp",
        "outputId": "59a082ee-e8fd-4b12-eb0e-8ed98c891012"
      },
      "source": [
        "# the data is already split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = load_data() #Notice how this is much cleaner than before.\n",
        "\n",
        "# Since we're dealing with image data, we need to reshape each vector\n",
        "# This lets our network learn using pixels that are close together\n",
        "#x_train, x_test = x_train / 255.0, x_test / 255.0 # consider uncommenting this to try with normalization\n",
        "x_train = x_train.reshape(len(x_train), 28, 28, 1)\n",
        "x_test = x_test.reshape(len(x_test), 28, 28, 1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdQVNW3a4g5m"
      },
      "source": [
        "Let's build our neural network again. This time, we'll have several convolutional layers.\n",
        "\n",
        "We'll start with the input layer. Since we have a 28x28 image, we need 784 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egfEAbZp4o1e",
        "outputId": "564170f5-fed3-44f1-de34-a4dad9cd126e"
      },
      "source": [
        "model = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ug-hL497PYD"
      },
      "source": [
        "Now, let's train the neural network!\n",
        "\n",
        "We'll start a little differently than before. First, we'll use minibatches. This lets us compute a noisy estimate of the gradients at each time step, helping speed up training and escape local minima.\n",
        "\n",
        "Additionally, we will randomly split the dataset into a training and validation set. Much like a test set, this will separate some of the images so they are NOT used for training. We can see how well the trained network is performing on new data as we go. This lets us tune parameters as we go to avoid overfitting.\n",
        "\n",
        "Finally, we'll save the best model as we go, so we keep the best model before overfitting starts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqBbGbg96-eW",
        "outputId": "3a14207e-1c06-45c7-bc43-84baaca12306"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('best_MNIST_CNN_model.hdf5', monitor='val_loss', save_best_only=True, save_freq=\"epoch\")\n",
        "callbacks_list=[model_checkpoint]\n",
        "\n",
        "model.fit(x=x_train,y=y_train, batch_size=50,epochs=10,verbose=1,validation_split=0.2,callbacks=callbacks_list)\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.5684 - accuracy: 0.8237 - val_loss: 0.0813 - val_accuracy: 0.9758\n",
            "Epoch 2/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0992 - accuracy: 0.9688 - val_loss: 0.0600 - val_accuracy: 0.9844\n",
            "Epoch 3/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.0479 - val_accuracy: 0.9867\n",
            "Epoch 4/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0629 - accuracy: 0.9798 - val_loss: 0.0419 - val_accuracy: 0.9871\n",
            "Epoch 5/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0549 - accuracy: 0.9824 - val_loss: 0.0440 - val_accuracy: 0.9863\n",
            "Epoch 6/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0512 - accuracy: 0.9834 - val_loss: 0.0389 - val_accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.0435 - val_accuracy: 0.9872\n",
            "Epoch 9/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0380 - val_accuracy: 0.9894\n",
            "Epoch 10/10\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0352 - val_accuracy: 0.9909\n",
            "313/313 - 1s - loss: 0.0278 - accuracy: 0.9906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02784702740609646, 0.9905999898910522]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6fT02rc7p1a"
      },
      "source": [
        "Wow! Nearly 99% accuracy, in under a minute.\n",
        "How can we do better?\n",
        "\n",
        "Let's go a little bigger, adding dense layers after our convolutional layers.\n",
        "\n",
        "\n",
        "We are going to recreate one of the very first convolutional neural networks\n",
        "\n",
        "#LeNet\n",
        "\n",
        "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljiu7dvF7kOX",
        "outputId": "ff71a1b9-f103-49c7-ea16-8cac9953df37"
      },
      "source": [
        "model2 = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(6, kernel_size=(5, 5), padding=\"same\", activation=\"tanh\"),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, kernel_size=(5, 5), activation=\"tanh\"),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(120, kernel_size=(5, 5), activation=\"tanh\"),\n",
        "    Flatten(),\n",
        "    Dense(84, activation=\"tanh\"),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='SGD',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 120)         48120     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKKJ9w6H-ln8"
      },
      "source": [
        "Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vbgN13B9Zqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58043348-9b1b-4d40-8b4d-f0553f7735d1"
      },
      "source": [
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch < 2:\n",
        "      return 5e-4\n",
        "    elif epoch < 5:\n",
        "      return 2e-4\n",
        "    elif epoch < 8:\n",
        "      return 1e-4\n",
        "    elif epoch < 12:\n",
        "      return 5e-5\n",
        "    else:\n",
        "      return 1e-5\n",
        "\n",
        "callbacks_list=[LearningRateScheduler(lr_scheduler, verbose=1)]\n",
        "\n",
        "model2.fit(x=x_train,y=y_train, batch_size=64,epochs=20,verbose=1,validation_split=0.2) #, callbacks=callbacks_list)\n",
        "model2.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 1.1283 - accuracy: 0.7119 - val_loss: 0.2924 - val_accuracy: 0.9302\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2765 - accuracy: 0.9306 - val_loss: 0.1779 - val_accuracy: 0.9564\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1745 - accuracy: 0.9544 - val_loss: 0.1329 - val_accuracy: 0.9659\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1368 - accuracy: 0.9627 - val_loss: 0.1123 - val_accuracy: 0.9695\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1128 - accuracy: 0.9690 - val_loss: 0.1000 - val_accuracy: 0.9734\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1029 - accuracy: 0.9699 - val_loss: 0.0912 - val_accuracy: 0.9755\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0927 - accuracy: 0.9743 - val_loss: 0.0840 - val_accuracy: 0.9768\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0810 - accuracy: 0.9769 - val_loss: 0.0815 - val_accuracy: 0.9779\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0814 - accuracy: 0.9756 - val_loss: 0.0753 - val_accuracy: 0.9791\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.9782 - val_loss: 0.0719 - val_accuracy: 0.9798\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.0684 - accuracy: 0.9799 - val_loss: 0.0703 - val_accuracy: 0.9806\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0668 - accuracy: 0.9794 - val_loss: 0.0664 - val_accuracy: 0.9816\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0664 - accuracy: 0.9797 - val_loss: 0.0633 - val_accuracy: 0.9823\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0618 - accuracy: 0.9821 - val_loss: 0.0625 - val_accuracy: 0.9819\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 0.0611 - val_accuracy: 0.9823\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.0574 - val_accuracy: 0.9837\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0536 - accuracy: 0.9841 - val_loss: 0.0567 - val_accuracy: 0.9837\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0507 - accuracy: 0.9854 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.0534 - val_accuracy: 0.9843\n",
            "313/313 - 0s - loss: 0.0468 - accuracy: 0.9851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04680196940898895, 0.9850999712944031]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Af3l1SJCS-"
      },
      "source": [
        "That's not much better, but we're using 1998 technology.\n",
        "\n",
        "Let's jump forward a few decades, by using ReLU activation, MaxPooling, Adam, and a Learning Rate Scheduler.\n",
        "\n",
        "That's a little better! But we're plateauing around 99%. Squeezing those last few bits of performance out is tricky, without some serious tweaks like data augmentation and ensemble networks.\n",
        "\n",
        "Okay, now let's go for state of the art.\n",
        "\n",
        "This is called SimpleNet: 13 convolutional layers, with Batch Normalization every layer, and Dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFWfigDuJSCT"
      },
      "source": [
        "# SimpleNet\n",
        "https://arxiv.org/pdf/1608.06037.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95mXT-vpJUbE"
      },
      "source": [
        "model3 = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Dropout(0.1),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Conv2D(512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(2048, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv2D(256, kernel_size=(1, 1), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEc3dF5lOh2G",
        "outputId": "67d66c48-ad10-46e7-f022-e1d8eda3bd84"
      },
      "source": [
        "model3.compile(optimizer = Adam(learning_rate=0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model3.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_88 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_88 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_89 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_90 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_91 (Batc (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_92 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_93 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_94 (Batc (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_95 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_96 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_97 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 4, 4, 2048)        1050624   \n",
            "_________________________________________________________________\n",
            "batch_normalization_98 (Batc (None, 4, 4, 2048)        8192      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 2048)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 4, 4, 256)         524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 2, 2, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_100 (Bat (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 5,506,314\n",
            "Trainable params: 5,497,226\n",
            "Non-trainable params: 9,088\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-t6mGaswdJT"
      },
      "source": [
        "That's a lot of parameters!\n",
        "\n",
        "As a result, this is going to take a little longer to train. Make sure you're connected to GPU runtime!\n",
        "\n",
        "We're also going to do a few tricks to make sure we get the best results.\n",
        "\n",
        "First, we'll make sure that we only save the best model. That way, if we start to overfit, we can resume training from what worked best.\n",
        "\n",
        "Next, we'll start with a high learning rate, then decrease it over time. This should help us escape some local minima, and keep learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzeWgDAOh38",
        "outputId": "87e0ba8f-9528-440d-c549-566570b9efd7"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('best_SimpleNet.hdf5', monitor='val_loss', save_best_only=True, save_freq=\"epoch\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=1, verbose=1, factor=0.2, min_lr=1e-6)\n",
        "\n",
        "callbacks_list=[model_checkpoint, reduce_lr]\n",
        "\n",
        "model3.fit(x=x_train,y=y_train, batch_size=100 ,epochs=10,verbose=1,validation_split=0.2,callbacks=callbacks_list)\n",
        "model3.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "480/480 [==============================] - 40s 79ms/step - loss: 0.5952 - accuracy: 0.8380 - val_loss: 0.1454 - val_accuracy: 0.9596\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0683 - accuracy: 0.9792 - val_loss: 0.0515 - val_accuracy: 0.9866\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.0440 - val_accuracy: 0.9871\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 38s 78ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.1037 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0237 - val_accuracy: 0.9937\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0237 - val_accuracy: 0.9937\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0212 - val_accuracy: 0.9945\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0220 - val_accuracy: 0.9946\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0215 - val_accuracy: 0.9948\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 37s 78ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0216 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
            "313/313 - 3s - loss: 0.0146 - accuracy: 0.9949\n",
            "6.345659414927165 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9uSwm42Kq2L"
      },
      "source": [
        "#SimpleNet Smol\n",
        "\n",
        "This takes the same ideas as above, but uses a 5x fewer parameters, and a special 2D version of Dropout after every BatchNorm layer to really try and avoid overfitting.\n",
        "\n",
        "Let's see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zj-2_Z2ckon"
      },
      "source": [
        "model4 = Sequential([\n",
        "    Input(shape=x_train[0].shape),\n",
        "    Conv2D(66, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "    Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(96, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(144, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding=\"same\"),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(144, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(178, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    SpatialDropout2D(0.2),\n",
        "\n",
        "    Conv2D(216, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(momentum=0.95),\n",
        "    GlobalMaxPooling2D(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation=\"softmax\"),\n",
        "])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH4bmhVXdarE",
        "outputId": "ea4a439d-33c7-41ad-8a68-2ed369a4b1c2"
      },
      "source": [
        "model4.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model4.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 28, 28, 66)        660       \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 28, 28, 66)        264       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 28, 28, 64)        38080     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 28, 28, 96)        55392     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 28, 28, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 14, 14, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 14, 14, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 14, 14, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 14, 14, 96)        83040     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 14, 14, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 14, 14, 144)       124560    \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 14, 14, 144)       576       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 144)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 7, 7, 144)         186768    \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 7, 7, 144)         576       \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 7, 7, 178)         230866    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 7, 7, 178)         712       \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 7, 7, 216)         346248    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 7, 7, 216)         864       \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_2 (Glob (None, 216)               0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 216)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2170      \n",
            "=================================================================\n",
            "Total params: 1,313,016\n",
            "Trainable params: 1,310,368\n",
            "Non-trainable params: 2,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3RfMxbydbg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493bbbdd-e89e-4e5d-a351-d377ac5e7bc6"
      },
      "source": [
        "model_checkpoint2 = ModelCheckpoint('best_SimpleNet_Smol.hdf5', monitor='val_loss', save_best_only=True, save_freq=\"epoch\")\n",
        "reduce_lr2 = ReduceLROnPlateau(monitor='val_accuracy', patience=1, verbose=1, factor=0.2, min_lr=1e-6)\n",
        "\n",
        "callbacks_list=[model_checkpoint2, reduce_lr2]\n",
        "\n",
        "model4.fit(x=x_train,y=y_train, batch_size=100 ,epochs=10,verbose=1,validation_split=0.2,callbacks=callbacks_list)\n",
        "model4.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "480/480 [==============================] - 25s 49ms/step - loss: 0.8329 - accuracy: 0.8456 - val_loss: 0.1771 - val_accuracy: 0.9548\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 23s 49ms/step - loss: 0.0891 - accuracy: 0.9730 - val_loss: 0.0731 - val_accuracy: 0.9808\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 0.0591 - val_accuracy: 0.9843\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0452 - accuracy: 0.9867 - val_loss: 0.0425 - val_accuracy: 0.9891\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0414 - val_accuracy: 0.9882\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0195 - val_accuracy: 0.9951\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0198 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0183 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0180 - val_accuracy: 0.9951\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 23s 48ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0180 - val_accuracy: 0.9949\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
            "313/313 - 2s - loss: 0.0120 - accuracy: 0.9960\n",
            "3.940545924504598 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}